{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IsbguCuioQ9a"
   },
   "source": [
    "# Stereo Matching with Pytorch\n",
    "\n",
    "## **Part 2: Learning based stereo matching**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kTDDcmhPoi2v"
   },
   "source": [
    "Rather than of using SSD/SAD to compute a matching cost for the disparity map, in this part we will train a network to directly learn that from the data instead. You'll be implementing what has been proposed in the paper [[Zbontar & LeCun, 2015]](https://arxiv.org/abs/1409.4326) and see how it performs compare to classical cost matching approaches.\n",
    "\n",
    "**Note:**\n",
    "As a reminder, this notebook is intendend to be run on [Google Colab](https://colab.research.google.com). So first upload to Google Drive, and then change the runtime to use GPU by select \"Runtime\" -> \"Change runtime time\" -> \"Hardward accelerator\". Select \"GPU\" and click \"Save\".\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9qEqq1Gvts-c"
   },
   "source": [
    "## Set up "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qDNH_AnAt0oo"
   },
   "source": [
    "Here we will download neccessary data and set up the environment. You can skip this if the data files is still in your colab environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1T15O22mwGnE"
   },
   "outputs": [],
   "source": [
    "#download and extract the data -- training data\n",
    "!rm subtest_bin.zip\n",
    "!wget http://ec2-18-217-54-78.us-east-2.compute.amazonaws.com:8787/subtest_bin.zip && unzip subtest_bin.zip\n",
    "    \n",
    "#files\n",
    "#!wget http://ec2-18-217-54-78.us-east-2.compute.amazonaws.com:8787/sgm.py .\n",
    "!rm custom_utils.py\n",
    "!wget http://ec2-18-217-54-78.us-east-2.compute.amazonaws.com:8787/custom_utils.py .\n",
    "    \n",
    "## Download and extract the data for the appropriate window size -- pre-trained network\n",
    "\n",
    "!rm mc_cnn_network_pretrain_*\n",
    "!wget http://ec2-18-217-54-78.us-east-2.compute.amazonaws.com:8787/mc_cnn_network_pretrain_ws11.pth -O mc_cnn_network_pretrain_ws11.pth\n",
    "!wget http://ec2-18-217-54-78.us-east-2.compute.amazonaws.com:8787/mc_cnn_network_pretrain_ws5.pth -O mc_cnn_network_pretrain_ws5.pth \n",
    "!wget http://ec2-18-217-54-78.us-east-2.compute.amazonaws.com:8787/mc_cnn_network_pretrain_ws9.pth -O mc_cnn_network_pretrain_ws9.pth \n",
    "!wget http://ec2-18-217-54-78.us-east-2.compute.amazonaws.com:8787/mc_cnn_network_pretrain_ws15.pth -O mc_cnn_network_pretrain_ws15.pth "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hXj3N8uhtcEZ"
   },
   "outputs": [],
   "source": [
    "\n",
    "#import torch and set tensor type\n",
    "import torch\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "use_cuda = True and torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "tensor_type = torch.cuda.FloatTensor if use_cuda else torch.FloatTensor\n",
    "torch.set_default_tensor_type(tensor_type)\n",
    "\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.manual_seed(333) #do not change this, this is to ensure your result is reproduciable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hXjPIipCzGag"
   },
   "source": [
    "## DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IdK2HbLbzKTz"
   },
   "source": [
    "We already stored all the training data in the .bin format, so we simply need to load them up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PebRPqmZ73tX"
   },
   "outputs": [],
   "source": [
    "#this is loading up all the data to train\n",
    "from custom_utils import loadbin, DataLoader\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "data_dir = 'subtest_bin/'\n",
    "\n",
    "nnz = loadbin(f'{data_dir}/mb_valid_disp_coord.bin')\n",
    "\n",
    "X, dispnoc = DataLoader(data_dir)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "f05xFB1hNavv"
   },
   "outputs": [],
   "source": [
    "#visualize the data\n",
    "#pick image for testing\n",
    "ind_img = 2\n",
    "print('Left Image')\n",
    "plt.imshow(X[ind_img][0][0][0][0].cpu().numpy(),cmap=\"gray\")\n",
    "plt.show()\n",
    "print('Right Image')\n",
    "plt.imshow(X[ind_img][0][0][1][0].cpu().numpy(),cmap=\"gray\")\n",
    "plt.show()\n",
    "print('Ground Truth disparity')\n",
    "plt.imshow(dispnoc[ind_img].cpu().numpy(), cmap='jet')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Bwq02eqpNbTq"
   },
   "source": [
    "# Network Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kv7dNEXhko6f"
   },
   "source": [
    "In this part, **you** will be implementing **MCNET** network architecture as described in the paper. We will follow the description of the accurate network for Middlebury dataset, see the instruction page for the network diagram. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JRBI6guyCEAe"
   },
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "from custom_utils import save_model, load_model\n",
    "\n",
    "class Reshape(nn.Module):\n",
    "    def __init__(self, shape):\n",
    "        super(Reshape, self).__init__()\n",
    "        self.shape = shape\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x.view(*self.shape)\n",
    "      \n",
    "      \n",
    "class MCNET(torch.nn.Module):\n",
    "    \"\"\"\n",
    "\n",
    "    MCNET based on paper from [Zbontar & LeCun, 2015]. This network takes as input two patches of size 11x11 and output the \n",
    "    likelihood of the two patches being a match. \n",
    "\n",
    "    Args:\n",
    "    -   ws: window size (or blocking size) of the input patch\n",
    "    -   batch_size: batch size \n",
    "    Returns:\n",
    "    -   matching cost between the 2 patches, we use 0 for positive match (represent 0 cost to match) and 1 for negative match\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, ws = 11, batch_size=512, load_path = None, strict=True):\n",
    "        super(MCNET, self).__init__()\n",
    "        \n",
    "        num_feature_map = 112 \n",
    "        kernel_size = 3\n",
    "        num_hidden_unit = 384\n",
    "        self.batch_size = batch_size\n",
    "        self.ws = ws\n",
    "        self.strict = strict\n",
    "\n",
    "        self.net = nn.Sequential(\n",
    "            ############################################################################\n",
    "            # Student code begin\n",
    "            ############################################################################\n",
    "            raise NotImplementedError('MCNET not implemented')\n",
    "            ############################################################################\n",
    "            # Student code end\n",
    "            ############################################################################\n",
    "\n",
    "        ).to(device)\n",
    "\n",
    "        self.criterion = nn.BCELoss().to(device)\n",
    "        if load_path is not None:\n",
    "          self.net = load_model(self.net,load_path, strict=strict)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        return self.net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZJypr_YeqSob"
   },
   "outputs": [],
   "source": [
    "######################################################################\n",
    "#this block will act as a unit test for your MCNET architecture. There are 2 tests here\n",
    "#1) test that your network output the correct size\n",
    "#2) test that you can load up a pre-trained network with the correct architecture. \n",
    "#Make sure you are able to run it without any error. \n",
    "from custom_utils import verify, test_mcnet\n",
    "\n",
    "net_tr = MCNET(ws=11,batch_size=1)\n",
    "print('Testing for MCNET:', verify(test_mcnet,net_tr))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iU2QOM0cFARW"
   },
   "outputs": [],
   "source": [
    "######################################################################\n",
    "#To experiment with different architecture, you can set strict=False which allow for partial loading \n",
    "#of the weight parameters, \n",
    "\n",
    "#You can also train from scratch by setting load_path to None\n",
    "#######################################################################\n",
    "\n",
    "net_tr = MCNET(ws=11,load_path = 'mc_cnn_network_pretrain_ws11.pth',strict=True)\n",
    "\n",
    "print(net_tr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ClfXult5xWz3"
   },
   "source": [
    "**Deliverables:** Network architecture implementation in MCNET and copy the output of `print(net_tr)` above to the report.\n",
    "\n",
    "\n",
    "**Questions**: \n",
    "1.   What's the purpose of ReLU and why do we add it after every conv and fc layers?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yLxlKZa4NfGJ"
   },
   "source": [
    "# Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-ASSV4XIQClJ"
   },
   "outputs": [],
   "source": [
    "def gen_patch(image, x, y, ws = 11):\n",
    "    \"\"\"\n",
    "    function to return a patch of size ws at a specific location of the image.\n",
    "    x, y in this case is a top left corner of the patch, for example if x,y is (0,0)\n",
    "    you should return a patch over (0,0) and (ws,ws)\n",
    "    \n",
    "    For corner case, you can pad the output with zeros such that we always have \n",
    "    (channel, ws, ws) dimension output\n",
    "    \n",
    "    Args:\n",
    "    -   image: image of type Tensor with dimension (channel, width, height)\n",
    "    -   x: x location in the image \n",
    "    -   y: y location in the image\n",
    "    -   ws: window size or block size of the patch we want\n",
    "    Returns:\n",
    "    -   patch: a patch of size (channel, ws, ws) of type Tensor\n",
    "\n",
    "    \"\"\"\n",
    "    ############################################################################\n",
    "    # Student code begin\n",
    "    ############################################################################\n",
    "    \n",
    "    raise NotImplementedError('gen_patch not implemented')\n",
    "    ############################################################################\n",
    "    # Student code end\n",
    "    ############################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "p2btva1fqbQg"
   },
   "outputs": [],
   "source": [
    "######################################################################\n",
    "#this block will act as a unit test for your gen_patch function. \n",
    "\n",
    "from custom_utils import verify, test_gen_patch\n",
    "\n",
    "print('Testing for gen_patch:', verify(test_gen_patch,gen_patch))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sKpfx5gHuKiJ"
   },
   "source": [
    "Here is an example of positive and negative match that we will use to train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tXgjSNiFuEAf"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "from custom_utils import get_disparity\n",
    "\n",
    "ind = 423267#np.random.randint(0,len(nnz))\n",
    "\n",
    "img, dim3, dim4, d = get_disparity(nnz,ind)\n",
    "\n",
    "d_pos = 0\n",
    "d_neg = torch.Tensor(1).uniform_(5,25)\n",
    "\n",
    "if torch.Tensor(1) < 0.5:\n",
    "    d_neg = -d_neg\n",
    "\n",
    "x0 = X[int(img)][0][0,0]\n",
    "x1 = X[int(img)][0][0,1]\n",
    "\n",
    "anchor = gen_patch(x0, dim3, dim4)\n",
    "pos = gen_patch(x1, dim3, dim4 - d + d_pos)\n",
    "neg = gen_patch(x1, dim3, dim4 - d + d_neg)\n",
    "\n",
    "fig = plt.figure(figsize=(12,4))\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.imshow(anchor[0].cpu().numpy(),cmap='gray')\n",
    "plt.title('Patch from image A')\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.imshow(pos[0].cpu().numpy(),cmap='gray')\n",
    "plt.title('Positive patch from image B')\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.imshow(neg[0].cpu().numpy(),cmap='gray')\n",
    "plt.title('Negative patch from image B')\n",
    "\n",
    "fig.suptitle('Patch examples')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MqG4tbzm04sX"
   },
   "source": [
    "**Deliverables:** Implement gen_patch() function and copy the patch example above to the report\n",
    "\n",
    "**Questions:** \n",
    "1.   Giving a true disparity map for each stereo pair, how do we extract positive and negative patches for the training?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iwqg4QKDuBdU"
   },
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_GdYb7H8xLDM"
   },
   "source": [
    "In the following part, the goal is to train a network that learn how to classify 2 patches as positive vs negative match. Your task is to train a best network by experimenting with the learning parameters below. There is no coding required in this part, but you should familiarize yourself with how the training and tuning parameters work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0NIVdSF_Hv34"
   },
   "outputs": [],
   "source": [
    "def run_net(model, nnz, batch_size, ws=11,  max_epoch=1, split='train', optimizer=None, viz_frequency=1, save_frequency=200, fname=\"mc_cnn_network.pth\"):\n",
    "    epoch = 1\n",
    "    loss_history = []\n",
    "    perm = torch.randperm(nnz.size(0))\n",
    "    for t in range(1,int(len(nnz) - batch_size // 2),batch_size // 2):\n",
    "        x_batch_tr = torch.zeros(batch_size*2, 1, ws, ws).type(tensor_type).to(device)\n",
    "        y_batch_tr = torch.zeros(batch_size).type(tensor_type).to(device)\n",
    "        x_batch_tr_ = torch.zeros(x_batch_tr.size()).to(device)\n",
    "        y_batch_tr_ = torch.zeros(y_batch_tr.size()).to(device)\n",
    "        for i in range(1,batch_size//2 + 1):\n",
    "            d_pos = 0\n",
    "            d_neg = torch.Tensor(1).uniform_(1.5,18)\n",
    "\n",
    "            if torch.rand(1) < 0.5:\n",
    "                d_neg = -d_neg\n",
    "\n",
    "            ind = perm[t+i-2]\n",
    "            img, dim3, dim4, d = get_disparity(nnz,ind)\n",
    "            \n",
    "            if split=='train':\n",
    "                if img == ind_img: # Leave out 1 image for validation\n",
    "                    continue\n",
    "            elif split=='test':\n",
    "                if img != ind_img: # Only operate on validation image\n",
    "                    continue\n",
    "\n",
    "            if len(X[int(img)]) == 0:\n",
    "                continue\n",
    "\n",
    "            x0 = X[int(img)][0][0,0]\n",
    "            x1 = X[int(img)][0][0,1]\n",
    "\n",
    "            #normalize image\n",
    "            x0 = x0.add(-x0.mean()).div(x0.std())\n",
    "            x1 = x1.add(-x1.mean()).div(x1.std())\n",
    "\n",
    "            x_batch_tr_[i * 4 - 4] = gen_patch(x0, dim3, dim4, ws=ws)\n",
    "            x_batch_tr_[i * 4 - 3] = gen_patch(x1, dim3, dim4 - d + d_pos, ws=ws)\n",
    "            x_batch_tr_[i * 4 - 2] = gen_patch(x0,  dim3, dim4, ws=ws)\n",
    "            x_batch_tr_[i * 4 - 1] = gen_patch(x1, dim3, dim4 - d + d_neg, ws=ws)\n",
    "\n",
    "            y_batch_tr_[i*2-2] = 0\n",
    "            y_batch_tr_[i*2-1] = 1\n",
    "\n",
    "        x_batch_tr = (x_batch_tr_).clone()\n",
    "        y_batch_tr = (y_batch_tr_).clone()\n",
    "\n",
    "        output = model(x_batch_tr)\n",
    "        loss = model.criterion(output,y_batch_tr.view(batch_size,1))\n",
    "        if split == 'train':\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            if epoch == 1 or ((epoch) % save_frequency) == 0:\n",
    "                save_model(model.net,fname)\n",
    "                \n",
    "        if ((epoch) % viz_frequency) == 0:\n",
    "            print(f'Iteration: {epoch}, Loss: {loss.data}')\n",
    "\n",
    "        epoch = epoch + 1\n",
    "        loss_history.append(loss.data.cpu().numpy())\n",
    "        if epoch > max_epoch: # ge instead of > ?\n",
    "            break\n",
    "    return loss_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5eMOnlucEoMv"
   },
   "outputs": [],
   "source": [
    "#train\n",
    "import math\n",
    "import time\n",
    "st = time.time()\n",
    "\n",
    "viz_frequency = 5\n",
    "save_frequency = 50 #for saving model\n",
    "\n",
    "############# EXPERIMENT WITH THESE ########\n",
    "\n",
    "#you can change this to load up pretrain network for other window size\n",
    "net_tr = MCNET(ws=11,load_path = 'mc_cnn_network_pretrain_ws11.pth',strict=True) \n",
    "\n",
    "max_epoch = 200\n",
    "learning_rate = 0.0001\n",
    "\n",
    "optimizer = torch.optim.Adam(net_tr.net.parameters(), lr=learning_rate)\n",
    "#optimizer = torch.optim.SGD(net_tr.net.parameters(), lr=learning_rate, momentum=0.9)\n",
    "############################################\n",
    "\n",
    "batch_size = net_tr.batch_size\n",
    "ws = net_tr.ws\n",
    "\n",
    "loss_history = run_net(model=net_tr,\n",
    "                       nnz=nnz, \n",
    "                       batch_size=batch_size, \n",
    "                       ws=ws, \n",
    "                       max_epoch=max_epoch, \n",
    "                       split='train', \n",
    "                       optimizer=optimizer,\n",
    "                       viz_frequency=viz_frequency, \n",
    "                       save_frequency=save_frequency,\n",
    "                       fname = 'mc_cnn_network_ws11.pth'\n",
    "                      )\n",
    "\n",
    "print('Time elasped: ', time.time() - st) \n",
    "\n",
    "print('Training Loss')\n",
    "plt.plot(loss_history)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cPNwZd4mAn-n"
   },
   "outputs": [],
   "source": [
    "def evaluate_network(network):\n",
    "\n",
    "  #compute loss on the held out validation set \n",
    "  #nnz_val = nnz#loadbin(f'{data_dir}/mb_valid_disp_coord_val.bin')\n",
    "\n",
    "  num_test_epochs = 50\n",
    "  \n",
    "  batch_size = network.batch_size\n",
    "  ws = network.ws\n",
    "\n",
    "  loss_history = run_net(model=network,\n",
    "                         nnz=nnz, \n",
    "                         batch_size=batch_size, \n",
    "                         ws=ws, \n",
    "                         max_epoch=num_test_epochs, \n",
    "                         split='test', \n",
    "                         viz_frequency=num_test_epochs+1, \n",
    "                         save_frequency=save_frequency)\n",
    "  \n",
    "   #validation_loss))\n",
    "  return np.mean(np.array(loss_history))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cqOpI0nVA8Nl"
   },
   "outputs": [],
   "source": [
    "net_te = MCNET(ws=11, load_path = 'mc_cnn_network_ws11.pth')\n",
    "val_loss = evaluate_network(net_te)\n",
    "\n",
    "print('Final average validation loss:', val_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4xWbgWVbxJ2Z"
   },
   "source": [
    "The network will be saved in `mc_cnn_network_vanilla.pth` or whatever name you set, this is the final saved model you'll need to run other part of the project. You can download a copy of this from colab so that you don't lost progress if anything goes wrong."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mmJa0Me8kVxa"
   },
   "source": [
    "**Deliverables:** train the network to achieve the lowest error as possible. Copy the training loss plot and the final validation loss to the report.\n",
    "\n",
    "**Questions:** \n",
    "\n",
    "\n",
    "1.   How does changing learning rate (try using large (> 1) vs small value (< 1e-5)) effect the training? Why do you think that's the case?\n",
    "2.   What's the difference between Adam and SGD? What do you notice when switching between them?\n",
    "3.   Is your validation loss lower or higher than your training loss? What is the reason for that? How would we get a better validation loss?\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Vw80iwlCNos6"
   },
   "source": [
    "# Modifying the Network for Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wBTrn5N8ubBN"
   },
   "source": [
    "Here we will experiment with adding layers and varying window size and observe the effect this has on overall performance. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PHQtq8b7uRz_"
   },
   "source": [
    "## Vary window size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6H6vosltNotN"
   },
   "source": [
    "In the previous section, we use window size of 11 as suggested in the paper, meaning that the input to the network will be patches of size 11x11. This corresponds to the block size that will be used when perform stereo matching later on.\n",
    "\n",
    "In this part we would like you to experiment with other window size, namely 5x5, 9x9, and 15x15 and compare the performance. You can set this in the previous cell for training,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MkNTGCP4Z-JS"
   },
   "source": [
    "**Deliverables:** Training loss curves and validation loss for window sizes of 5, 9, 15 added to the report.\n",
    "\n",
    "\n",
    "**Questions**: \n",
    "1.   What's the effect of varying the window size on performance? Do you suppose there is an optimal window size for all images? Explain why or why not. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6mwZZH9Xa_4q"
   },
   "source": [
    "## Vary Network Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "REkhaqf1D8zi"
   },
   "source": [
    "Using your favorite window size (note it in the report), we will be varying the architecture slightly to see how this effects training and performance. In `CustomModule` you can add any network architecture that you want. For our purposes, simply add an additional fully-connected layer of the same size for training. We can access the full list of layers of a model using: \n",
    "\n",
    "```*list(model.children())``` \n",
    "\n",
    "HINT: The final linear layer non-linearity of the original network should be removed, replaced with a ReLU, and added to the end of your new layer! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GMRxhWx1fmV4"
   },
   "outputs": [],
   "source": [
    "class ExtendedNet(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    For adding layers to a previously defined network.\n",
    "    \n",
    "    Args:\n",
    "    -   ws: window size (or blocking size) of the input patch\n",
    "    -   batch_size: batch size \n",
    "    Returns:\n",
    "    -   matching cost between the 2 patches, we use 0 for positive match (represent 0 cost to match) and 1 for negative match\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, orig_model, ws = 11, batch_size=512, new_layer_size = 384, load_path=None, strict=True):\n",
    "        super(ExtendedNet, self).__init__()\n",
    "        \n",
    "        self.batch_size = batch_size\n",
    "        self.ws = ws\n",
    "        self.strict = strict\n",
    "\n",
    "        self.net = nn.Sequential(\n",
    "            ############################################################################\n",
    "            # Student code begin\n",
    "            ############################################################################\n",
    "            raise NotImplementedError('ExtendedNet not implemented')\n",
    "            ############################################################################\n",
    "            # Student code end\n",
    "            ############################################################################\n",
    "        ).to(device)\n",
    "        \n",
    "        self.criterion = nn.BCELoss().to(device)\n",
    "        \n",
    "        if load_path is not None:\n",
    "            self.net = load_model(self.net,load_path, strict=strict)     \n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        return self.net(x)\n",
    "      \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ECQt-mL8fmV-"
   },
   "outputs": [],
   "source": [
    "######################################################################\n",
    "#this block will act as a unit test for your extension of the  MCNET architecture. We will load up a pre-trained network of the \n",
    "#same architecture. Make sure you are able to run it without any error. \n",
    "\n",
    "#To experiment with different architecture, you can set strict=False which allow for partial loading \n",
    "#of the weight parameters, \n",
    "\n",
    "#You can also train from scratch by setting load_path to None\n",
    "#######################################################################\n",
    "\n",
    "######STUDENT CODE HERE##########\n",
    "ws = 11 #pick your favorite window size (from the pretrained sizes available)\n",
    "#################################\n",
    "\n",
    "from custom_utils import verify, test_extendednet\n",
    "\n",
    "\n",
    "net_tr = MCNET(ws=ws, load_path = f'mc_cnn_network_pretrain_ws{ws}.pth',strict=True)\n",
    "print(net_tr)\n",
    "\n",
    "net_extended = ExtendedNet(orig_model=net_tr, ws=ws, batch_size=512, strict=True)\n",
    "print(net_extended)\n",
    "\n",
    "print('Testing for MCNET:', verify(test_extendednet,net_extended))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uTrWLft-C35O"
   },
   "outputs": [],
   "source": [
    "st = time.time()\n",
    "\n",
    "viz_frequency = 5\n",
    "save_frequency = 200 #for saving model\n",
    "\n",
    "max_epoch = 200\n",
    "learning_rate = 0.0001\n",
    "\n",
    "optimizer = torch.optim.Adam(net_extended.net.parameters(), lr=learning_rate)\n",
    "\n",
    "batch_size = net_extended.batch_size\n",
    "ws = net_extended.ws\n",
    "\n",
    "loss_history = run_net(model=net_extended,\n",
    "                       nnz=nnz, \n",
    "                       batch_size=batch_size, \n",
    "                       ws=ws, \n",
    "                       max_epoch=max_epoch, \n",
    "                       split='train', \n",
    "                       optimizer=optimizer,\n",
    "                       viz_frequency=viz_frequency, \n",
    "                       save_frequency=save_frequency,\n",
    "                       fname='mc_cnn_network_extend.pth'\n",
    "                      )\n",
    "\n",
    "print('Time elasped: ', time.time() - st) \n",
    "\n",
    "print('Training Loss')\n",
    "plt.plot(loss_history)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "s1ZfP2jZbiSG"
   },
   "outputs": [],
   "source": [
    "#compute loss on the held out validation set \n",
    "\n",
    "net_te = MCNET(ws=ws)\n",
    "net_extended = ExtendedNet(orig_model=net_te, ws=ws, batch_size=512, load_path='mc_cnn_network_extend.pth', strict=True)\n",
    "\n",
    "# orig_model, ws = 11, batch_size=512, new_layer_size = 384, load_path=None, strict=True\n",
    "\n",
    "batch_size = net_extended.batch_size\n",
    "ws = net_extended.ws\n",
    "\n",
    "val_loss = evaluate_network(net_extended)\n",
    "\n",
    "print('Final average validation loss:', val_loss) #validation_loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LcoRIkFDfmWD"
   },
   "source": [
    "**Deliverables:** New network architecture that extends MCNET, the loss curve from training it, and the validation accuracy of the new network. Copy the output of `print(net_extended)`, the training loss, and the final mean validation loss to the report.\n",
    "\n",
    "\n",
    "**Questions**: \n",
    "1.   What's the effect of adding more layers without adding more data?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gg-fs8MZpZcy"
   },
   "source": [
    "# Evaluate stereo matching"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8a7_tKRUpx1c"
   },
   "source": [
    "For this part we will again generate the disparity map but this time from our newly trained matching cost network instead of SAD/SSD. You should first **upload 2 files from part 1 (similarity_measures.py, disparity_map.py)** into colab environment. Click at the `>` sign on the top left, choose `Files` tab, then upload the 2 files into the current directory.\n",
    "\n",
    "Note that all the required functions in part 1 need to be implemented correctly before starting this part. Use this part to evaluate your trained network as a stereo matching cost.  \n",
    "\n",
    "Hint: You don't have to re-train the network every time you want to evaluate, as long as your saved model is in Colab file system. Don't forget to change `load_path` to your best model,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2AcNsIRqABs6"
   },
   "outputs": [],
   "source": [
    "###########Change to your best model here################\n",
    "\n",
    "net_te = MCNET(batch_size = 1, load_path = 'mc_cnn_network_ws11.pth')\n",
    "\n",
    "#net_extended = ExtendedNet(orig_model=net_te, ws=ws, batch_size=512, load_path='mc_cnn_network_extend.pth', strict=True)\n",
    "\n",
    "############################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DZBTTD5rr4ga"
   },
   "outputs": [],
   "source": [
    "try:\n",
    "  from similarity_measures import sad_similarity_measure,ssd_similarity_measure\n",
    "  from disparity_map import calculate_disparity_map\n",
    "except ModuleNotFoundError:\n",
    "  print('\\033[91m Error: please upload disparity_map.py and similarity_measures.py from part 1\\033[0m ')\n",
    "from custom_utils import loadbin, DataLoader\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "\n",
    "#loading images from our testing set\n",
    "\n",
    "try:\n",
    "  assert len(X) is not None #dummy code to check if X exists\n",
    "except NameError:\n",
    "  #load up data again in case we start from this part\n",
    "  data_dir = 'subtest_bin/'\n",
    "\n",
    "  nnz_te = loadbin(f'{data_dir}/mb_valid_disp_coord.bin')\n",
    "  nnz = nnz_te\n",
    "\n",
    "  X, dispnoc = DataLoader(nnz_te, data_dir)\n",
    "  ind_img = 2\n",
    "    \n",
    "scale = 5\n",
    "im_left = X[ind_img][0][0][0][0][::scale,::scale]\n",
    "im_right = X[ind_img][0][0][1][0][::scale,::scale]\n",
    "im_dispnoc = dispnoc[ind_img][::scale,::scale]\n",
    "im_dispnoc_full = dispnoc[ind_img]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KTkzNpmHsjHb"
   },
   "outputs": [],
   "source": [
    "fig, (ax1, ax2, ax3) = plt.subplots(1,3)\n",
    "fig.set_figheight(5)\n",
    "fig.set_figwidth(5*3)\n",
    "\n",
    "ax1.imshow(im_left.cpu().numpy(), cmap=\"gray\")\n",
    "ax1.title.set_text('Left image')\n",
    "\n",
    "ax2.imshow(im_right.cpu().numpy(), cmap=\"gray\")\n",
    "ax2.title.set_text('Right image')\n",
    "\n",
    "ax3.imshow(im_dispnoc.cpu().numpy(), cmap=\"jet\")\n",
    "ax3.title.set_text('Ground Truth disparity')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OTGNZIoWs_4f"
   },
   "outputs": [],
   "source": [
    "# extract a patch of interest from the left image\n",
    "patch_left_img = im_left[80:91, 85:96]\n",
    "\n",
    "# get the search area in the right image\n",
    "search_area_right_img = (im_right[80:91, 60:102])\n",
    "\n",
    "plt.imshow(patch_left_img.cpu().numpy(), cmap='gray')\n",
    "plt.show()\n",
    "plt.imshow(search_area_right_img.cpu().numpy(),cmap='gray')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UrgKkg7YU-3e"
   },
   "outputs": [],
   "source": [
    "def cnn_similarity_measure(patch1, patch2, ws=11):\n",
    "    \"\"\"\n",
    "\n",
    "    \"\"\"\n",
    "    assert patch1.shape==patch2.shape\n",
    "\n",
    "    if isinstance(patch1,np.ndarray) or isinstance(patch2,np.ndarray):\n",
    "      patch1 = torch.tensor(patch1)\n",
    "      patch2 = torch.tensor(patch2)\n",
    "      \n",
    "    patch1 = patch1.unsqueeze(0).unsqueeze(0)\n",
    "    patch2 = patch2.unsqueeze(0).unsqueeze(0)\n",
    "    patch1 = patch1.add(-patch1.mean()).div(patch1.std()).reshape(1,1,ws,ws)\n",
    "    patch2 = patch2.add(-patch2.mean()).div(patch2.std()).reshape(1,1,ws,ws)\n",
    "\n",
    "\n",
    "    x = torch.cat((patch1,patch2),0)[:,:,:,:]\n",
    "    output = net_te(x.to(device))[0][0]\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2Ijk3zPLqvCH"
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12,4))\n",
    "\n",
    "similarity_vals = np.array([sad_similarity_measure(patch_left_img, search_area_right_img[:,h_idx:(h_idx+11)]) for h_idx in range(search_area_right_img.shape[1]-10)])\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.plot(similarity_vals)\n",
    "plt.title('SSD')\n",
    "\n",
    "similarity_vals = np.array([ssd_similarity_measure(patch_left_img, search_area_right_img[:,h_idx:(h_idx+11)]) for h_idx in range(search_area_right_img.shape[1]-10)])\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.plot(similarity_vals)\n",
    "plt.title('SAD')\n",
    "\n",
    "similarity_vals = np.array([cnn_similarity_measure(patch_left_img, search_area_right_img[:,h_idx:(h_idx+11)]) for h_idx in range(search_area_right_img.shape[1]-10)])\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.plot(similarity_vals)\n",
    "plt.title('MC-CNN')\n",
    "fig.suptitle('Matching cost comparison')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pVBaGlMrzgeF"
   },
   "source": [
    "**Deliverables:** copy the matching cost comparison to the report\n",
    "\n",
    "**Questions:**\n",
    "\n",
    "\n",
    "1.   Based on the matching cost comparison plot, how are SSD, SAD, and MC-CNN different? Can you think of a scenario where matching with MC-CNN would be prefered over SSD/SAD?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sWfLNz2iPpwJ"
   },
   "source": [
    "The following cell can take around **an hour** to run, we suggest you only run this at the end when you are confident in the network you trained and want to evaluate the results. (HINT: your validation loss should be lower than 0.3 before you proceed.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BDJhxZxRU8U-"
   },
   "outputs": [],
   "source": [
    "# calculate the disparity map with block size of 11 this will take awhile\n",
    "st = time.time()\n",
    "disp_map = calculate_disparity_map((im_left.unsqueeze(0).transpose(2,0).transpose(0,1)), #swap the channel\n",
    "                                   (im_right.unsqueeze(0).transpose(2,0).transpose(0,1)), \n",
    "                                   block_size=11, \n",
    "                                   sim_measure_function = sad_similarity_measure,\n",
    "                                   max_search_bound = 30)\n",
    "\n",
    "disp_map_cnn = calculate_disparity_map(im_left.unsqueeze(0).transpose(2,0).transpose(0,1), \n",
    "                                   im_right.unsqueeze(0).transpose(2,0).transpose(0,1), \n",
    "                                   block_size=11, \n",
    "                                   sim_measure_function = cnn_similarity_measure,\n",
    "                                   max_search_bound = 30)\n",
    "print('Time Elasped:', time.time() - st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ecj_vKSjnhld"
   },
   "outputs": [],
   "source": [
    "from cv2 import resize\n",
    "def evaluate_stereo(gt, disp):\n",
    "  \n",
    "  max_disp = 280\n",
    "  mask = gt!=np.inf\n",
    "\n",
    "  if disp.shape != gt.shape:\n",
    "    ratio = float(gt.shape[1])/disp.shape[1]\n",
    "    disp=resize(disp,(gt.shape[0],gt.shape[1])).transpose()*ratio\n",
    "  disp[disp>max_disp]=max_disp\n",
    "  \n",
    "  errmap = np.abs(gt-disp)*mask\n",
    "  avgerr = errmap[mask].mean()\n",
    "  bad1map = (errmap>1) * mask\n",
    "  bad1 = bad1map[mask].sum()/float(mask.sum())*100 #percentage of bad pixels whose error is greater than 1\n",
    "\n",
    "  bad2map = (errmap>2) * mask\n",
    "  bad2 = bad2map[mask].sum()/float(mask.sum())*100\n",
    "\n",
    "  bad4map = (errmap>4) * mask\n",
    "  bad4 = bad4map[mask].sum()/float(mask.sum())*100\n",
    "  \n",
    "  return avgerr, bad1, bad2, bad4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QK9O6JBQq34N"
   },
   "outputs": [],
   "source": [
    "fig, (ax1, ax2, ax3) = plt.subplots(1,3)\n",
    "fig.set_figheight(5)\n",
    "fig.set_figwidth(5*3)\n",
    "\n",
    "ax1.imshow(im_left.cpu().numpy(), cmap=\"gray\")\n",
    "ax1.title.set_text('Left image')\n",
    "\n",
    "ax2.imshow(im_right.cpu().numpy(), cmap=\"gray\")\n",
    "ax2.title.set_text('Right image')\n",
    "\n",
    "ratio = float(im_dispnoc_full.shape[1])/disp_map.shape[1] #ratio for the actual disparity in pixel\n",
    "\n",
    "ax3.imshow(im_dispnoc.cpu().numpy()/ratio, cmap=\"jet\", interpolation='nearest')\n",
    "ax3.title.set_text('Ground Truth disparity')\n",
    "fig, (ax4, ax5) = plt.subplots(1,2)\n",
    "fig.set_figheight(5)\n",
    "fig.set_figwidth(5*2)\n",
    "\n",
    "ax4.imshow((disp_map.cpu().numpy()), cmap='jet', interpolation='nearest')\n",
    "ax4.title.set_text('SAD Disparity map')\n",
    "\n",
    "ax5.imshow((disp_map_cnn.cpu().numpy().astype(np.float32)), cmap='jet', interpolation='nearest')\n",
    "ax5.title.set_text('MCCNN Disparity map')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "cnn_avgerr, cnn_bad1, cnn_bad2, cnn_bad4 = evaluate_stereo(im_dispnoc_full.cpu().numpy(),disp_map_cnn.cpu().numpy().astype(np.float32))\n",
    "sad_avgerr,  sad_bad1, sad_bad2, sad_bad4 = evaluate_stereo(im_dispnoc_full.cpu().numpy(),disp_map.cpu().numpy().astype(np.float32))\n",
    "\n",
    "\n",
    "print('--------------------------------------------------------------------------')\n",
    "print('Metrics: \\t\\t', 'SAD','\\t\\t\\t','MCCNN')\n",
    "print('--------------------------------------------------------------------------')\n",
    "print('Average Error \\t\\t',sad_avgerr,'\\t\\t', cnn_avgerr)\n",
    "print('%error > 1 pixel\\t', sad_bad1,'\\t',cnn_bad1)\n",
    "print('%error > 2 pixels\\t',sad_bad2, '\\t',cnn_bad2)\n",
    "print('%error > 4 pixels\\t',sad_bad4, '\\t', cnn_bad4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hRb8jP6uyPp7"
   },
   "source": [
    "**Deliverables:** Make a screen shot of the disparity map and the evaluation results above and copy them to the report.\n",
    "\n",
    "**Questions:**\n",
    "\n",
    "\n",
    "1.   Qualitatively, between SAD and MCCNN, which disparity map do you think looks better? Explain your reasoning.\n",
    "2.   Quantitatively, between SAD and MCCNN, which one acieve better score on the metrics? Why do you think that's the case?\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "mc_cnn.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

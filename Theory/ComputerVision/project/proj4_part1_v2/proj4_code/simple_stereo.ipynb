{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from proj4_code.utils import load_image, PIL_resize, generate_random_stereogram, stereo_helper_fn\n",
    "from proj4_code.disparity_map import calculate_disparity_map\n",
    "from proj4_code.similarity_measures import ssd_similarity_measure, sad_similarity_measure\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from unit_tests.test_base import verify\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use a helper function called stereo_helper_fn for utils.py for calculating and plotting the disparity maps using the functions defined by you"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random dot stereogram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Deliverables**:\n",
    "All the disparity maps\n",
    "+\n",
    "Observations and Analysis:\n",
    "1. What is the effect of increasing the block size? \n",
    "2. Why is the result poor on the left edge and not on the other edges?\n",
    "\n",
    "Note that implementations in disparity_map.py and similarity_measures.py should be completed before this section can work. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate left and right images\n",
    "im_left, im_right = generate_random_stereogram(im_size=(51, 51, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from unit_tests.test_utils import test_generate_random_stereogram\n",
    "\n",
    "print('Test for random dot stereogram', verify(test_generate_random_stereogram))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement the similarity function and disparity map calculation. You will need it in the next steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from unit_tests.test_similarity_measures import (\n",
    "  test_ssd_similarity_measure_values, \n",
    "  test_sad_similarity_measure_values, \n",
    "  test_similarity_measure_size_compatibility\n",
    ")\n",
    "\n",
    "print('Testing value for SAD measure', verify(test_sad_similarity_measure_values))\n",
    "print('Testing value for SSD measure', verify(test_ssd_similarity_measure_values))\n",
    "print('Testing input size compatibility for measures', verify(test_similarity_measure_size_compatibility))\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from unit_tests.test_disparity_map import (\n",
    "  test_disparity_deltafn_failure,\n",
    "  test_disparity_deltafn_success,\n",
    "  test_disparity_map_size,\n",
    "  test_disparity_random_stereogram,\n",
    "  test_disparity_translation_shift\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Testing for disparity map on a delta function', verify(test_disparity_deltafn_failure))\n",
    "print('Testing for disparity map on a delta function', verify(test_disparity_deltafn_success))\n",
    "print('Testing disparity map size', verify(test_disparity_map_size))\n",
    "print('Testing random stereogram ouptut', verify(test_disparity_random_stereogram))\n",
    "print('Testing disparity on translation shift', verify(test_disparity_translation_shift))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stereo_helper_fn(im_left, im_right, block_size = [3,5,9,13], max_search_bound=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Error profile analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before computing the full disparity map, we will analyse the similarity error between patches. You will have to find out different patches in the image which exhibit a close-to-convex error profile, and a highly non-convex profile.\n",
    "\n",
    "**Deliverable**:\n",
    "Find the patch in the left image and search space in the right image, and the similarity error plot for the two cases, and copy it to the report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the image\n",
    "base_path = '../data/adirondack/'\n",
    "im_left = PIL_resize(load_image(base_path + 'im_left.png'), (0.1, 0.1))\n",
    "im_right = PIL_resize(load_image(base_path + 'im_right.png'), (0.1, 0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1,2, figsize=(10,10))\n",
    "\n",
    "ax1.imshow(im_left, interpolation=None)\n",
    "ax1.title.set_text('Left image')\n",
    "ax1.autoscale(False)\n",
    "ax1.set_axis_on()\n",
    "\n",
    "ax2.imshow(im_right, interpolation=None)\n",
    "ax2.title.set_text('Right image')\n",
    "ax2.autoscale(False)\n",
    "ax2.set_axis_on()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convex error profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# extract a patch of interest from the left image\n",
    "patch_size=15\n",
    "x_idx, y_idx = (62, 65) #(None, None) # TODO: replace with integers\n",
    "patch_left_img = torch.tensor(im_left[x_idx:x_idx+patch_size+1, y_idx:y_idx+patch_size+1,:])\n",
    "plt.imshow(patch_left_img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the search area in the right image\n",
    "max_search_bound = 30 # might need adjustment based on your (x_idx, y_idx)\n",
    "search_area_right_img = torch.tensor(\n",
    "  im_right[x_idx:x_idx+patch_size+1, y_idx-max_search_bound:y_idx+patch_size+1,:]\n",
    ")\n",
    "plt.imshow(search_area_right_img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity_vals = np.array(\n",
    "  [sad_similarity_measure(patch_left_img, search_area_right_img[:,h_idx:h_idx+patch_size+1,:]) \n",
    "   for h_idx in range(search_area_right_img.shape[1]-patch_size-1)\n",
    "  ])\n",
    "plt.plot(similarity_vals)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Non-Convex error profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# extract a patch of interest from the left image\n",
    "patch_size=15\n",
    "x_idx, y_idx = (150, 190) #(None, None) # TODO: replace with integers\n",
    "patch_left_img = torch.tensor(im_left[x_idx:x_idx+patch_size+1, y_idx:y_idx+patch_size+1,:])\n",
    "plt.imshow(patch_left_img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the search area in the right image\n",
    "max_search_bound = 40 # might need adjustment based on your (x_idx, y_idx)\n",
    "search_area_right_img = torch.tensor(\n",
    "  im_right[x_idx:x_idx+patch_size+1, y_idx-max_search_bound:y_idx+patch_size+1,:]\n",
    ")\n",
    "plt.imshow(search_area_right_img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity_vals = np.array(\n",
    "  [sad_similarity_measure(patch_left_img, search_area_right_img[:,h_idx:h_idx+patch_size+1,:]) \n",
    "   for h_idx in range(search_area_right_img.shape[1]-patch_size-1)\n",
    "  ])\n",
    "plt.plot(similarity_vals)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Real life stereo images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "stereo_helper_fn(torch.tensor(im_left), torch.tensor(im_right), max_search_bound=25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Deliverables**\n",
    "1. Copy the disparity map for the patch size you feel works the best\n",
    "2. Can you think of an explanation as to why the back rest of the chair appears *blocky*?\n",
    "\n",
    "Tip: you can see all the examples and deliverables before answering. This will help you understand the core ideas being asked."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = '../data/bicycle/'\n",
    "im_left = PIL_resize(load_image(base_path + 'im_left.png'), (0.1, 0.1))\n",
    "im_right = PIL_resize(load_image(base_path + 'im_right.png'), (0.1, 0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stereo_helper_fn(torch.tensor(im_left), torch.tensor(im_right), block_size=[11], max_search_bound=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = '../data/bowling/'\n",
    "im_left = PIL_resize(load_image(base_path + 'im_left.png'), (0.2, 0.2))\n",
    "im_right = PIL_resize(load_image(base_path + 'im_right.png'), (0.2, 0.2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "stereo_helper_fn(torch.tensor(im_left), torch.tensor(im_right), block_size=[9], max_search_bound=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = '../data/bowling2/'\n",
    "im_left = PIL_resize(load_image(base_path + 'im_left.png'), (0.20, 0.20))\n",
    "im_right = PIL_resize(load_image(base_path + 'im_right.png'), (0.20, 0.20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stereo_helper_fn(torch.tensor(im_left), torch.tensor(im_right), block_size=[9], max_search_bound=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Deliverables** of set 3 and set 4 combined:\n",
    "\n",
    "1. Copy the disparity maps from set 4 in the report\n",
    "2. Can you spot a peculiar behaviour of the diaprity maps near the head of bowling pin on the right? What do you see in the input images in that area? Can you figure out the reason behind this behaviour?\n",
    "3. Notice that we have manipulated the images in set 4 to generate set 4 images. This leads to a difference in disparity map results in the bottom of the image and on the green bowling ball. Can you explain why the disparity drops to zero in both these regions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = '../data/flowers/'\n",
    "im_left = PIL_resize(load_image(base_path + 'im_left.png'), (0.10, 0.10))\n",
    "im_right = PIL_resize(load_image(base_path + 'im_right.png'), (0.10, 0.10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stereo_helper_fn(torch.tensor(im_left), torch.tensor(im_right), block_size=[9], max_search_bound=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observations**: (these observations do not go in the report. These are for your understanding).\n",
    "\n",
    "1. Notice the different disparity of the flower at the back and its shadow\n",
    "2. Spot the zero-disparity region in the center of the house\n",
    "3. See how smooth the disparity values are on the couch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = '../data/stairs/'\n",
    "im_left = PIL_resize(load_image(base_path + 'im_left.jpg'), (1, 1))\n",
    "im_right = PIL_resize(load_image(base_path + 'im_right.jpg'), (1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stereo_helper_fn(torch.tensor(im_left), torch.tensor(im_right), block_size = [3, 5, 7], max_search_bound=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Deliverables**\n",
    "\n",
    "1. Why are we able to see the shift in disparity values on the wall?\n",
    "2. What is the effect of block_size and the ability to see stairs-like structure in the disparity map?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Smoothing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One issue with the results from is that they aren't very smooth. Pixels next to each other on the same surface can have vastly different disparities, making the results look very noisy and patchy in some areas. Intuitively, pixels next to each other should have a smooth transition in disparity(unless at an object boundary or occlusion).\n",
    "In this section, we try to improve our results. One way of doing this is through the use of a smoothing constraint. The smoothing method we use is called Semi-Global Matching(SGM) or Semi-Global Block Matching. Before, we picked the disparity for a pixel based on the minimum matching cost of the block using some metric(SSD or SAD). The basic idea of SGM is to penalize pixels with a disparity that's very different than their neighbors by adding a penalty term on top of the matching cost term. SGM tries to minimize the global(over the entire image) energy function\n",
    "\\begin{equation*}\n",
    "E(D) \\leq \\sum_{p} (C(p, D_p) + \\sum_{q} PT(|D_p - D_q|))\n",
    "\\end{equation*}\n",
    "C(p,D_p) is the matching cost for a pixel with disparity D_p, q is a neighboring pixel, and PT is some penalty function penalizing the difference in disparities.\n",
    "You can read more about how this method works and is optimized here:\n",
    "https://elib.dlr.de/73119/1/180Hirschmueller.pdf\n",
    "and\n",
    "https://pdfs.semanticscholar.org/bcd8/4d8bd864ff903e3fe5b91bed3f2eedacc324.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we implement the smoothing algorithm, we need to implement a function which computes the **cost volume**. We have already written code to compute disparity map. We will extend that code to compute the cost volume. Instead of taking the argmin of the similarity error profile, we will store the tensor of error profile at each pixel location along the third dimension.\n",
    "\n",
    "If we have an input image of dimension (H,W,C) and max search bound of D, the cost_volume will be a tensor of dimension (H,W,D). The cost volumne at (i,j) pixel is the error profile obtained for the patch in the left image centered at (i,j).\n",
    "\n",
    "Implement this part as function ```calculate_cost_volume``` in ```disparity_map.py```. Feel free to reuse any code you have written till now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from unit_tests.test_disparity_map import (\n",
    "  test_calculate_cost_volume\n",
    ")\n",
    "\n",
    "print('Testing for calculate_cost_volume', verify(test_calculate_cost_volume))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the image\n",
    "from semiglobalmatching.sgm import sgm\n",
    "from scipy import ndimage\n",
    "from proj4_code.similarity_measures import sad_similarity_measure, ssd_similarity_measure\n",
    "\n",
    "#you can change the path to try other pairs, but you may need to fix the scaling per pair\n",
    "base_path = '../data/adirondack/'\n",
    "im_left = PIL_resize(load_image(base_path + 'im_left.png'), (0.10, 0.10))\n",
    "im_right = PIL_resize(load_image(base_path + 'im_right.png'), (0.10, 0.10))\n",
    "\n",
    "#calculates the disparity map with SGM, the last argument is max disparity to consider\n",
    "disparity_map = sgm(im_left,im_right, \"result\", 30, sad_similarity_measure, 9)\n",
    "result = ndimage.median_filter(disparity_map, size=5)\n",
    "plt.figure()\n",
    "plt.imshow(result, cmap='jet', interpolation='nearest')\n",
    "plt.title('Disparity map')\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Deliverables**\n",
    "\n",
    "1. Compare these results qualitatively to the output of the chair image without smoothing.\n",
    "2. What regions of the image does smoothing seem to perform better on and why do you think that is?\n",
    "3. What regions of the image does smoothing seem to perform worse on and why do you think that is?\n",
    "4. Would smoothing still work for images with both a horizontal and vertical shift?\n",
    "\n",
    "\n",
    "(Extra Credit)Try the above smoothing with your own image pair! Take 2 images with only(or mostly) a horizontal shift, and see the result by editing the image paths and running the code. If you get good results, explain why your image pair is \"easy\". If you get bad results, explain why your pair is \"hard\". These results go in the extra credit slides. "
   ]
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

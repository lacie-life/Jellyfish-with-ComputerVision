{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Scene Recognition with Bag-of-Words](https://dellaert.github.io/19F-4476/proj5.html)\n",
    "For this project, you will need to report performance for two\n",
    "combinations of features / classifiers. It is suggested you code them in\n",
    "this order, as well:\n",
    "1. Tiny image features and nearest neighbor classifier\n",
    "2. Bag of sift features and nearest neighbor classifier\n",
    "\n",
    "The starter code is initialized to 'placeholder' just so that the starter\n",
    "code does not crash when run unmodified and you can get a preview of how\n",
    "results are presented."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up parameters, image paths and category list\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# import cv2\n",
    "import numpy as np\n",
    "import os.path as osp\n",
    "import pickle\n",
    "from random import shuffle\n",
    "import matplotlib.pyplot as plt\n",
    "from proj5_code.utils import *\n",
    "import proj5_code.student_code as sc\n",
    "\n",
    "# Importing tests\n",
    "from proj5_unit_tests.test_student_code import (test_build_vocabulary_shape,\n",
    "    test_build_vocabulary_values, test_get_bags_of_sifts, \n",
    "    test_get_tiny_images_size, test_get_tiny_images_values, \n",
    "    test_kmeans_quantize_exact_matches, test_kmeans_quantize_noisy_continuous, \n",
    "    test_kmeans_2_classes_1d_features, test_kmeans_5_classes_2d_features,\n",
    "    test_nearest_neighbor_classify,\n",
    "    test_nearest_neighbor_classify_k, verify, test_pairwise_distances)\n",
    "\n",
    "# This is the list of categories / directories to use. The categories are\n",
    "# somewhat sorted by similarity so that the confusion matrix looks more\n",
    "# structured (indoor and then urban and then rural).\n",
    "categories = ['Kitchen', 'Store', 'Bedroom', 'LivingRoom', 'Office', 'Industrial', 'Suburb',\n",
    "              'InsideCity', 'TallBuilding', 'Street', 'Highway', 'OpenCountry', 'Coast',\n",
    "              'Mountain', 'Forest'];\n",
    "# This list of shortened category names is used later for visualization\n",
    "abbr_categories = ['Kit', 'Sto', 'Bed', 'Liv', 'Off', 'Ind', 'Sub',\n",
    "                   'Cty', 'Bld', 'St', 'HW', 'OC', 'Cst',\n",
    "                   'Mnt', 'For'];\n",
    "\n",
    "# Number of training examples per category to use. Max is 100. For\n",
    "# simplicity, we assume this is the number of test cases per category, as\n",
    "# well.\n",
    "num_train_per_cat = 100\n",
    "\n",
    "# This function returns lists containing the file path for each train\n",
    "# and test image, as well as lists with the label of each train and\n",
    "# test image. By default all four of these lists will have 1500 elements\n",
    "# where each element is a string.\n",
    "data_path = osp.join('..', 'data')\n",
    "# train_image_paths, test_image_paths, train_labels, test_labels = get_image_paths(data_path,\n",
    "#                                                                                  categories,\n",
    "#                                                                                  num_train_per_cat);\n",
    "train_image_arrays, test_image_arrays, train_labels, test_labels = get_image_arrays(data_path,\n",
    "                                                                                 categories,\n",
    "                                                                               num_train_per_cat)\n",
    "if len(train_image_arrays) == 0:\n",
    "    print(data_path, 'not found')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 1: Tiny Image features with Nearest Neighbor classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 1a: Pairwise distances\n",
    "\n",
    "In order to perform nearest neighbor classification, we'll need a distance metric. In `pairwise_distances()` you'll be implementing a Euclidean distance method. Recall that in 2D, the Euclidean distance between two vectors $X = [x_1, x_2]$ and $Y = [y_1, y_2]$ is defined as\n",
    "\n",
    "$$dist(X, Y) = \\sqrt{(y_1 - x_1)^2 + (y_2 - x_2)^2}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"test_pairwise_distances():\" + verify(test_pairwise_distances))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 1a: Represent each image with the Tiny Image feature\n",
    "\n",
    "Each function to construct features should return an N x d numpy array, where N is the number of paths passed to the function and d is the dimensionality of each image representation. See the starter code for each function for more details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Using the TINY IMAGE representation for images')\n",
    "\n",
    "train_image_feats = sc.get_tiny_images(train_image_arrays)\n",
    "test_image_feats = sc.get_tiny_images(test_image_arrays)\n",
    "\n",
    "print(\"test_get_tiny_images_size():\" + verify(test_get_tiny_images_size))\n",
    "print(\"test_get_tiny_images_values():\" + verify(test_get_tiny_images_values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 1b: Classify each test image by training and using the Nearest Neighbor classifier\n",
    "\n",
    "To run this cell you will need to implement the nearest neighbor classifier. See the function stub for details.\n",
    "\n",
    "Each function to classify test features will return an N element list, where N is the number of test cases and each entry is a string indicating the predicted category for each test image. Each entry in 'predicted_categories' must be one of the 15 strings in 'categories', 'train_labels', and 'test_labels'. See the starter code for each function for more details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"test_nearest_neighbor_classify()\" + verify(test_nearest_neighbor_classify))\n",
    "print(\"test_nearest_neighbor_classify_k()\" + verify(test_nearest_neighbor_classify_k))\n",
    "\n",
    "print('Using NEAREST NEIGHBOR classifier to predict test set categories')\n",
    "\n",
    "predicted_categories = sc.nearest_neighbor_classify(train_image_feats, train_labels, test_image_feats, k = 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 1c: Build a confusion matrix and score the recognition system"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(You do not need to code anything in this section.)\n",
    "\n",
    "If we wanted to evaluate our recognition method properly we would train\n",
    "and test on many random splits of the data. You are not required to do so\n",
    "for this project.\n",
    "\n",
    "This function will create a confusion matrix and various image\n",
    "thumbnails each time it is called. View the confusion matrix to help interpret\n",
    "your classifier performance. Where is it making mistakes? Are the\n",
    "confusions reasonable?\n",
    "\n",
    "Interpreting your performance with 100 training examples per category:\n",
    "- accuracy  =   0 -> Your code is broken (probably not the classifier's fault! A classifier would have to be amazing to perform this badly).\n",
    "- accuracy ~= .07 -> Your performance is chance. Something is broken or you ran the starter code unchanged.\n",
    "- accuracy ~= .15 ~ .20 -> Rough performance with tiny images and nearest neighbor classifier. Performance goes up a few percentage points with K-NN instead of 1-NN.\n",
    "- accuracy ~= .20 -> Rough performance with tiny images and linear SVM classifier. The linear classifiers will have a lot of trouble trying to separate the classes and may be unstable (e.g. everything classified to one category)\n",
    "- accuracy ~= .40 ~ .50 -> Rough performance with bag of SIFT and nearest neighbor classifier. Can reach .60 with K-NN and different distance metrics.\n",
    "- accuracy ~= .60 -> You've gotten things roughly correct with bag of SIFT and a linear SVM classifier.\n",
    "- accuracy >= .70 -> You've also tuned your parameters well. E.g. number of clusters, SVM regularization, number of patches sampled when building vocabulary, size and step for dense SIFT features.\n",
    "- accuracy >= .80 -> You've added in spatial information somehow or you've added additional, complementary image features. This represents state of the art in Lazebnik et al 2006.\n",
    "- accuracy >= .85 -> You've done extremely well. This is the state of the art in the 2010 SUN database paper from fusing many  features. Don't trust this number unless you actually measure many random splits.\n",
    "- accuracy >= .90 -> You used modern deep features trained on much larger image databases.\n",
    "- accuracy >= .96 -> You can beat a human at this task. This isn't a realistic number. Some accuracy calculation is broken or your classifier is cheating and seeing the test labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "show_results(train_labels, test_labels, categories, abbr_categories,\n",
    "             predicted_categories)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 2: Bag of SIFT features with Nearest Neighbor classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 2a: Represent each image with the Bag of SIFT feature\n",
    "\n",
    "Now we will implement a more advanced feature set to describe our images - SIFT features! To build the SIFT vocabulary for bag of words, you will need to implement the k-means clustering algorithm and utilize it in your build vocabulary function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To begin with, we have provided you with a simple visual demo on how kmeans works. No need to write any code yet, run the next cell, and play around with the slider to check the kmeans clustering process. (Credits to teaching staff from CS6601; thank you Prof. Starner!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import *\n",
    "import matplotlib.pyplot as plt\n",
    "K = 3\n",
    "data = np.load('../proj5_unit_tests/test_data/kmeans.npz', allow_pickle=True)\n",
    "print(data)\n",
    "X = data['X']\n",
    "y = data['y']\n",
    "means_history = data['means']\n",
    "clusters_history = data['clu']\n",
    "\n",
    "# This is an interactive cell to see the progress of training your K-means algorithm.\n",
    "# Feel free to improve the visualization code and share it with your classmates on Piazza\n",
    "def get_cluster(i):\n",
    "    clusters = clusters_history[i] # Get the clusters from K-means' i-th iteration\n",
    "    plt.figure(None, figsize=(15,6)) # Set the plot size\n",
    "    plt.suptitle('Drag the slider to see the algorthm training progress')\n",
    "    ax1=plt.subplot(1, 2, 1)\n",
    "    ax1.set_title('K-means clsuters - step %d' % i)\n",
    "    for k in range(K):\n",
    "        plt.plot(X[clusters==k,0], X[clusters==k,1], '.')\n",
    "    # Just to get a flavour of how the data looks like\n",
    "    ax2=plt.subplot(1, 2, 2)\n",
    "    ax2.set_title('Ground truth clusters')\n",
    "    for i in np.unique(y):\n",
    "        ax2.plot(X[y==i,0],X[y==i,1],'.')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "interactive(get_cluster, i=(1,len(clusters_history)-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"test_kmeans_2_classes_1d_features()\" + verify(test_kmeans_2_classes_1d_features))\n",
    "print(\"test_kmeans_5_classes_2d_features()\" + verify(test_kmeans_5_classes_2d_features))\n",
    "\n",
    "print(\"test_kmeans_2_classes_1d_features()\" + verify(test_build_vocabulary_shape))\n",
    "print(\"test_kmeans_5_classes_2d_features()\" + verify(test_build_vocabulary_values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To create a new vocabulary, make sure `vocab_filename` is different than the old vocabulary, or delete the old one.\n",
    "\n",
    "**Important: note the logic for this cell: if the vocab file is present in the directory, then we'll proceed directly to getting SIFT representations; otherwise the vocab is built from scratch. The first time you run the cell, expect running time to be at least 10 minutes, as we are building the vocab as well as getting SIFT representations at the same time. Hence, make sure that you have passed all unit tests for this section before proceeding with the following cell!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('Using the BAG-OF-SIFT representation for images')\n",
    "\n",
    "vocab_filename = '../data/vocab2.pkl'\n",
    "if not osp.isfile(vocab_filename):\n",
    "    # Construct the vocabulary\n",
    "    print('No existing visual word vocabulary found. Computing one from training images')\n",
    "    vocab_size = 50  # Larger values will work better (to a point) but be much slower to compute\n",
    "    vocab = sc.build_vocabulary(train_image_arrays, vocab_size)\n",
    "    with open(vocab_filename, 'wb') as f:\n",
    "        pickle.dump(vocab, f)\n",
    "        print('{:s} saved'.format(vocab_filename))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have built our vocabulary of visual words, we will use it to process our training and testing images.\n",
    "\n",
    "You will need to implement two analagous functions to run the cell below\n",
    "\n",
    "**Note: running on the full dataset will take some time**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"test_kmeans_quantize_exact_matches()\" + verify(test_kmeans_quantize_exact_matches))\n",
    "print(\"test_kmeans_quantize_noisy_continuous()\" + verify(test_kmeans_quantize_noisy_continuous))\n",
    "\n",
    "print(\"test_get_bags_of_sifts()\" + verify(test_get_bags_of_sifts))\n",
    "\n",
    "with open(vocab_filename, 'rb') as f:\n",
    "    vocabulary = pickle.load(f)\n",
    "train_image_feats = sc.get_bags_of_sifts(train_image_arrays, vocabulary)\n",
    "test_image_feats = sc.get_bags_of_sifts(test_image_arrays, vocabulary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 2b: Classify each test image by training and using the Nearest Neighbor classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Using NEAREST NEIGHBOR classifier to predict test set categories')\n",
    "predicted_categories = sc.nearest_neighbor_classify(train_image_feats, train_labels, test_image_feats, k = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 2c: Build a confusion matrix and score the recognition system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_results(train_labels, test_labels, categories, abbr_categories,\n",
    "             predicted_categories)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "We have seen that a basic classifier as simple as kNN is sufficient to get this classification task done with around 50% accuracy; you may choose to experiment with SVM classifier, which can boost your performance up to 60%, but that's not required for this project.\n",
    "\n",
    "This shows you how things are done in the pre-deep learning era, and the result is, uh, okay. In the next project, you will learn how to implement an actual neural network to do the classification, where 80% ~ 90% accuracies can be achieved with ease."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

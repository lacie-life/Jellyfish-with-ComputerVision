{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Anchor boxes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Typically, a majority of objects have a similar shape – for example, in a majority of\n",
    "cases, a bounding box corresponding to an image of a person will have a greater\n",
    "height than width, and a bounding box corresponding to the image of a truck will\n",
    "have a greater width than height. Thus, we will have a decent idea of the height and\n",
    "width of the objects present in an image even before training the model (by inspecting\n",
    "the ground truths of bounding boxes corresponding to objects of various classes).\n",
    "Furthermore, in some images, the objects of interest might be scaled – resulting in a\n",
    "much smaller or much greater height and width than average – while still\n",
    "maintaining the aspect ratio (that is, height/width).\n",
    "Once we have a decent idea of the aspect ratio and the height and width of objects\n",
    "(which can be obtained from ground truth values in the dataset) present in our\n",
    "images, we define the anchor boxes with heights and widths representing the\n",
    "majority of objects' bounding boxes within our dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Typically, this is obtained by employing K-means clustering on top of the ground\n",
    "truth bounding boxes of objects present in images.\n",
    "Now that we understand how anchor boxes' heights and widths are obtained, we will\n",
    "learn about how to leverage them in the process:\n",
    "\n",
    "1. Slide each anchor box over an image from top left to bottom right.\n",
    "\n",
    "2. The anchor box that has a high intersection over union (IoU) with the\n",
    "object will have a label that mentions that it contains an object, and the\n",
    "others will be labeled 0:\n",
    "    - We can modify the threshold of the IoU by mentioning that if the IoU\n",
    "    is greater than a certain threshold, the object class is 1; if it is less than\n",
    "    another threshold, the object class is 0, and it is unknown otherwise.\n",
    "\n",
    "Once we obtain the ground truths as defined here, we can build a model that can\n",
    "predict the location of an object and also the offset corresponding to the anchor box to\n",
    "match it with ground truth."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Region Proposal Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An RPN trains a model to enable it to identify region proposals with a\n",
    "high likelihood of containing an object by performing the following steps:\n",
    "1. Slide anchor boxes of different aspect ratios and sizes across the image to\n",
    "fetch crops of an image.\n",
    "2. Calculate the IoU between the ground truth bounding boxes of objects in\n",
    "the image and the crops obtained in the previous step.\n",
    "3. Prepare the training dataset in such a way that crops with an IoU greater\n",
    "than a threshold contain an object and crops with an IoU less than a\n",
    "threshold do not contain an object.\n",
    "4. Train the model to identify regions that contain an object.\n",
    "5. Perform non-max suppression to identify the region candidate that has the\n",
    "highest probability of containing an object and eliminate other region\n",
    "candidates that have a high overlap with it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

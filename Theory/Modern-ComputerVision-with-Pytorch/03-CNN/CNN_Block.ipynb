{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building blocks of a CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CNNs are the most prominent architectures that are used when working on images.\n",
    "CNNs address the major limitations of deep neural networks that we saw in the\n",
    "previous section. Besides image classification, they also help with object detection,\n",
    "image segmentation, GANs, and many more – essentially, wherever we use images.\n",
    "Furthermore, there are different ways of constructing a convolutional neural network,\n",
    "and there are multiple pre-trained models that leverage CNNs to perform various\n",
    "tasks. Starting with this chapter, we will be using CNNs extensively.\n",
    "\n",
    "In the upcoming subsections, we will understand the fundamental building blocks of\n",
    "a CNN, which are as follows:\n",
    "\n",
    "- Convolutions\n",
    "- Filters\n",
    "- Strides and padding\n",
    "- Pooling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A convolution is basically multiplication between two matrices. As you saw in the\n",
    "previous chapter, matrix multiplication is a key ingredient of training a neural\n",
    "network. (We perform matrix multiplication when we calculate hidden layer values –\n",
    "which is a matrix multiplication of the input values and weight values connecting the\n",
    "input to the hidden layer. Similarly, we perform matrix multiplication to calculate\n",
    "output layer values.)\n",
    "\n",
    "\n",
    "To ensure we have a solid understanding of the convolution process, let's go through\n",
    "the following example.\n",
    "\n",
    "Let's assume we have two matrices we can use to perform convolution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is Matrix A:\n",
    "\n",
    "![imgs](./imgs/cnn0.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is Matrix B:\n",
    "\n",
    "\n",
    "![imgs](./imgs/cnn1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While performing the convolution operation, you are sliding Matrix B (the smaller\n",
    "matrix) over Matrix A (the bigger matrix). Furthermore, we are performing element to\n",
    "element multiplication between Matrix A and Matrix B, as follows:\n",
    "\n",
    "![imgs](imgs/cnn2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result of performing the preceding operations is as follows:\n",
    "\n",
    "![img](./imgs/cnn3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A filter is a matrix of weights that is initialized randomly at the start. The model\n",
    "learns the optimal weight values of a filter over increasing epochs.\n",
    "\n",
    "The concept of filters brings us to two different aspects:\n",
    "- What the filters learn about\n",
    "- How filters are represented"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In general, the more filters there are in a CNN, the more features of an image that the\n",
    "model can learn about. \n",
    "\n",
    "For now, we'll ensure that we have an intermediate understanding that the filters learn about different features\n",
    "present in the image. For example, a certain filter might learn about the ears of a cat\n",
    "and provide high activation (a matrix multiplication value) when the part of the\n",
    "image it is convolving with contains the ear of a cat.\n",
    "\n",
    "In the previous section, we learned that when we convolved one filter that has a size\n",
    "of 2 x 2 with a matrix that has a size of 4 x 4, we got an output that is 3 x 3 in\n",
    "dimension.\n",
    "\n",
    "However, if 10 different filters multiply the bigger matrix (original image), the result\n",
    "is 10 sets of the 3 x 3 output matrices.\n",
    "\n",
    "Furthermore, in a scenario where we are dealing with color images where there are\n",
    "three channels, the filter that is convolving with the original image would also have\n",
    "three channels, resulting in a single scalar output per convolution. Also, if the filters\n",
    "are convolving with an intermediate output – let's say of 64 x 112 x 112 in shape – the\n",
    "filter would have 64 channels to fetch a scalar output. In addition, if there are 512\n",
    "filters that are convolving with the output that was obtained in the intermediate layer,\n",
    "the output post convolution with 512 filters would be 512 x 111 x 111 in shape.\n",
    "\n",
    "To solidify our understanding of the output of filters further, let's take a look at the\n",
    "following diagram:\n",
    "\n",
    "![imgs](./imgs/cnn5.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the preceding diagram, we can see that the input image is multiplied by the filters\n",
    "that have the same depth as that of the input (which the filters are convolving with)\n",
    "and that the number of channels in the output of a convolution is as many as there are\n",
    "filters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Strides"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's understand the impact of stride by leveraging the same example that we saw in\n",
    "the Filter section. Furthermore, we'll stride Matrix B with a stride of 2 over Matrix A.\n",
    "The output of convolution with a stride of 2 is as follows:\n",
    "\n",
    "![img](./imgs/cnn6.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result of performing the preceding operations is as follows:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![img](./imgs/cnn7.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the preceding output has a lower dimension compared to the scenario\n",
    "where the stride was 1 (where the output shape was 3 x 3) since we now have a stride\n",
    "of 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Padding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the preceding case, we could not multiply the leftmost elements of the filter by the\n",
    "rightmost elements of the image. If we were to perform such matrix multiplication,\n",
    "we would pad the image with zeros. This would ensure that we can perform element\n",
    "to element multiplication of all the elements within an image with a filter.\n",
    "\n",
    "Let's understand padding by using the same example we used in the\n",
    "Convolution section.\n",
    "\n",
    "Once we add padding on top of Matrix A, the revised version of Matrix A will look as\n",
    "follows:\n",
    "\n",
    "![imgs](./imgs/cnn8.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the preceding matrix, we can see that we have padded Matrix A with zeros and\n",
    "that the convolution with Matrix B will not result in the output dimension being\n",
    "smaller than the input's dimension. This aspect comes in handy when we are working\n",
    "on residual network where we must add the output of the convolution to the original\n",
    "image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pooling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pooling aggregates information in a small patch. Imagine a scenario where the output\n",
    "of convolution activation is as follows:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![imgs](./imgs/cnn9.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The max pooling for this patch is 4. Here, we have considered the elements in this\n",
    "pool of elements and have taken the maximum value across all the elements present.\n",
    "\n",
    "Similarly, let's understand the max pooling for a bigger matrix:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![imgs](./imgs/cnn10.png)\n",
    "\n",
    "![imgs](./imgs/cnn11.png)\n",
    "\n",
    "![imgs](./imgs/cnn12.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Putting them all together"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far, we have learned about convolution, filters, and pooling, and their impact in\n",
    "reducing the dimension of an image. Now, we will learn about another critical\n",
    "component of a CNN – the flatten layer (fully connected layer) – before putting the\n",
    "three pieces we have learned about together.\n",
    "\n",
    "\n",
    "To understand the flattening process, we'll take the output of the pooling layer in the\n",
    "previous section and flatten the output. The output of flattening the pooling layer is\n",
    "as follows:\n",
    "\n",
    "${6, 8, 14, 16}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By doing this, we'll see that the flatten layer can be treated equivalent to the input\n",
    "layer. Once the flatten layer's (fully connected\n",
    "layer) values have been obtained, we can pass it through the hidden layer and then\n",
    "obtain the output for predicting the class of an image.\n",
    "\n",
    "The overall flow of a CNN is as follows:\n",
    "\n",
    "![imgs](./imgs/cnn13.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the preceding image, we can see the overall flow of a CNN model, where we are\n",
    "passing an image through convolution via multiple filters and then pooling (and in\n",
    "the preceding case, repeating the convolution and pooling process twice), before\n",
    "flattening the output of the final pooling layer. This forms the feature learning part of\n",
    "the preceding image.\n",
    "\n",
    "The operations of convolution and pooling constitute the feature learning section as\n",
    "filters help in extracting relevant features from images and pooling helps in\n",
    "aggregating information and thereby reducing the number of nodes at the flatten\n",
    "layer. (If we directly flatten the input image (which is 300 x 300 pixels in size, for\n",
    "example), we are dealing with 90K input values. If we have 90K input pixel values\n",
    "and 100K nodes in a hidden layer, we are looking at ~9 billion parameters, which is\n",
    "huge in terms of computation.)\n",
    "\n",
    "Convolution and pooling help in fetching a flattened layer that has a much smaller\n",
    "representation than the original image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How convolution and pooling help in image translation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we perform pooling, we can consider the output of the operation as an\n",
    "abstraction of a region (a small patch). This phenomenon comes in handy, especially\n",
    "when images are being translated.\n",
    "\n",
    "Think of a scenario where an image is translated by 1 pixel to the left. Once we\n",
    "perform convolution, activation, and pooling on top of it, we'll have reduced the\n",
    "dimension of the image (due to pooling), which means that a fewer number of pixels\n",
    "store the majority of the information from the original image. Moreover, given that\n",
    "pooling stores information of a region (patch), the information within a pixel of the\n",
    "pooled image would not vary, even if the original image is translated by 1 unit. This\n",
    "is because the maximum value of that region is likely to get captured in the pooled\n",
    "image.\n",
    "\n",
    "Convolution and pooling cam also help us with the receptive field. To understand\n",
    "the receptive field, let's imagine a scenario where we perform a convolution pooling\n",
    "operation twice on an image that is 100 x 100 in shape. The output at the end of the\n",
    "two convolution pooling operations is of the shape 25 x 25 (if the convolution\n",
    "operation was done with padding). Each cell in the 25 x 25 output now corresponds to\n",
    "a larger 4 x 4 portion of the original image. Thus, because of the convolution and\n",
    "pooling operations, each cell in the resulting image corresponds to a patch of the\n",
    "original image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

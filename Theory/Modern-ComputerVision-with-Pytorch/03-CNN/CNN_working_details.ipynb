{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Building a CNN-based architecture using PyTorch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The CNN architecture will differ from the neural network architecture that we built\n",
        "in the previous chapter in that a CNN constitutes the following in addition to what a\n",
        "typical vanilla deep neural network would have:\n",
        "- Convolution operation\n",
        "- Pooling operation\n",
        "- Flattening layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "nJnTbZVIF55X"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/lacie/.local/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import TensorDataset, Dataset, DataLoader\n",
        "from torch.optim import SGD, Adam\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "from torchvision import datasets\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "CW87aBN_F7h5"
      },
      "outputs": [],
      "source": [
        "X_train = torch.tensor([[[[1,2,3,4],[2,3,4,5],[5,6,7,8],[1,3,4,5]]],[[[-1,2,3,-4],[2,-3,4,5],[-5,6,-7,8],[-1,-3,-4,-5]]]]).to(device).float()\n",
        "X_train /= 8\n",
        "y_train = torch.tensor([0,1]).to(device).float()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "WDr-XS8HF_UG"
      },
      "outputs": [],
      "source": [
        "def get_model():\n",
        "    model = nn.Sequential(\n",
        "        nn.Conv2d(1, 1, kernel_size=3),\n",
        "        nn.MaxPool2d(2),\n",
        "        nn.ReLU(),\n",
        "        nn.Flatten(),\n",
        "        nn.Linear(1, 1),\n",
        "        nn.Sigmoid(),\n",
        "    ).to(device)\n",
        "    loss_fn = nn.BCELoss()\n",
        "    optimizer = Adam(model.parameters(), lr=1e-2)\n",
        "    return model, loss_fn, optimizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 474
        },
        "id": "alInllQdGC13",
        "outputId": "3ab3e397-93c2-4f14-f325-6fb304bf2d66"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting torch_summary\n",
            "  Downloading torch_summary-1.4.5-py3-none-any.whl (16 kB)\n",
            "Installing collected packages: torch_summary\n",
            "Successfully installed torch_summary-1.4.5\n",
            "==========================================================================================\n",
            "Layer (type:depth-idx)                   Output Shape              Param #\n",
            "==========================================================================================\n",
            "├─Conv2d: 1-1                            [-1, 1, 2, 2]             10\n",
            "├─MaxPool2d: 1-2                         [-1, 1, 1, 1]             --\n",
            "├─ReLU: 1-3                              [-1, 1, 1, 1]             --\n",
            "├─Flatten: 1-4                           [-1, 1]                   --\n",
            "├─Linear: 1-5                            [-1, 1]                   2\n",
            "├─Sigmoid: 1-6                           [-1, 1]                   --\n",
            "==========================================================================================\n",
            "Total params: 12\n",
            "Trainable params: 12\n",
            "Non-trainable params: 0\n",
            "Total mult-adds (M): 0.00\n",
            "==========================================================================================\n",
            "Input size (MB): 0.00\n",
            "Forward/backward pass size (MB): 0.00\n",
            "Params size (MB): 0.00\n",
            "Estimated Total Size (MB): 0.00\n",
            "==========================================================================================\n"
          ]
        }
      ],
      "source": [
        "!pip install torch_summary\n",
        "from torchsummary import summary\n",
        "model, loss_fn, optimizer = get_model()\n",
        "summary(model, X_train);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "NqnAmC52GEz0"
      },
      "outputs": [],
      "source": [
        "def train_batch(x, y, model, opt, loss_fn):\n",
        "    model.train()\n",
        "    prediction = model(x)\n",
        "    batch_loss = loss_fn(prediction, y)\n",
        "    batch_loss.backward()\n",
        "    optimizer.step()\n",
        "    optimizer.zero_grad()\n",
        "    return batch_loss.item()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "GPFRvgAlGIbp"
      },
      "outputs": [],
      "source": [
        "trn_dl = DataLoader(TensorDataset(X_train, y_train))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "yHALwqudGJzh",
        "outputId": "1104beb4-326c-4ad7-8952-a5056c73bf9b"
      },
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "Using a target size (torch.Size([1])) that is different to the input size (torch.Size([1, 1])) is deprecated. Please ensure they have the same size.",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[7], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[39mfor\u001b[39;00m ix, batch \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(\u001b[39miter\u001b[39m(trn_dl)):\n\u001b[1;32m      3\u001b[0m     x, y \u001b[39m=\u001b[39m batch\n\u001b[0;32m----> 4\u001b[0m     batch_loss \u001b[39m=\u001b[39m train_batch(x, y, model, optimizer, loss_fn)\n",
            "Cell \u001b[0;32mIn[5], line 4\u001b[0m, in \u001b[0;36mtrain_batch\u001b[0;34m(x, y, model, opt, loss_fn)\u001b[0m\n\u001b[1;32m      2\u001b[0m model\u001b[39m.\u001b[39mtrain()\n\u001b[1;32m      3\u001b[0m prediction \u001b[39m=\u001b[39m model(x)\n\u001b[0;32m----> 4\u001b[0m batch_loss \u001b[39m=\u001b[39m loss_fn(prediction, y)\n\u001b[1;32m      5\u001b[0m batch_loss\u001b[39m.\u001b[39mbackward()\n\u001b[1;32m      6\u001b[0m optimizer\u001b[39m.\u001b[39mstep()\n",
            "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
            "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/loss.py:613\u001b[0m, in \u001b[0;36mBCELoss.forward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    612\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor, target: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 613\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mbinary_cross_entropy(\u001b[39minput\u001b[39;49m, target, weight\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, reduction\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mreduction)\n",
            "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/functional.py:3074\u001b[0m, in \u001b[0;36mbinary_cross_entropy\u001b[0;34m(input, target, weight, size_average, reduce, reduction)\u001b[0m\n\u001b[1;32m   3072\u001b[0m     reduction_enum \u001b[39m=\u001b[39m _Reduction\u001b[39m.\u001b[39mget_enum(reduction)\n\u001b[1;32m   3073\u001b[0m \u001b[39mif\u001b[39;00m target\u001b[39m.\u001b[39msize() \u001b[39m!=\u001b[39m \u001b[39minput\u001b[39m\u001b[39m.\u001b[39msize():\n\u001b[0;32m-> 3074\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   3075\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mUsing a target size (\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m) that is different to the input size (\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m) is deprecated. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   3076\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mPlease ensure they have the same size.\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(target\u001b[39m.\u001b[39msize(), \u001b[39minput\u001b[39m\u001b[39m.\u001b[39msize())\n\u001b[1;32m   3077\u001b[0m     )\n\u001b[1;32m   3079\u001b[0m \u001b[39mif\u001b[39;00m weight \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   3080\u001b[0m     new_size \u001b[39m=\u001b[39m _infer_size(target\u001b[39m.\u001b[39msize(), weight\u001b[39m.\u001b[39msize())\n",
            "\u001b[0;31mValueError\u001b[0m: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([1, 1])) is deprecated. Please ensure they have the same size."
          ]
        }
      ],
      "source": [
        "for epoch in range(2000):\n",
        "    for ix, batch in enumerate(iter(trn_dl)):\n",
        "        x, y = batch\n",
        "        batch_loss = train_batch(x, y, model, optimizer, loss_fn)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "YMEA3dcUGMA2",
        "outputId": "db7abd8c-c17a-4b1c-9f4d-37795420c05f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[0.0042]], grad_fn=<SigmoidBackward>)"
            ]
          },
          "execution_count": 8,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model(X_train[:1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eHErutP4GNxI"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        },
        "id": "Zw-Ou9J4Gail",
        "outputId": "3b16cd39-beef-429a-947d-3d2cc86d0398"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[Conv2d(1, 1, kernel_size=(3, 3), stride=(1, 1)),\n",
              " MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False),\n",
              " ReLU(),\n",
              " Flatten(start_dim=1, end_dim=-1),\n",
              " Linear(in_features=1, out_features=1, bias=True),\n",
              " Sigmoid()]"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "list(model.children())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3ACidFxRGa_0"
      },
      "outputs": [],
      "source": [
        "(cnn_w, cnn_b), (lin_w, lin_b) = [(layer.weight.data, layer.bias.data) for layer in list(model.children()) if hasattr(layer, 'weight')]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lj-SiW6sGcyy"
      },
      "outputs": [],
      "source": [
        "h_im, w_im = X_train.shape[2:]\n",
        "h_conv, w_conv = cnn_w.shape[2:]\n",
        "sumprod = torch.zeros((h_im - h_conv + 1, w_im - w_conv + 1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RPPgrk51GgL1"
      },
      "outputs": [],
      "source": [
        "for i in range(h_im - h_conv + 1):\n",
        "    for j in range(w_im - w_conv + 1):\n",
        "        img_subset = X_train[0, 0, i:(i+3), j:(j+3)]\n",
        "        model_filter = cnn_w.reshape(3,3)\n",
        "        val = torch.sum(img_subset*model_filter) + cnn_b\n",
        "        sumprod[i,j] = val"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "GqaZ2WlpGjTN",
        "outputId": "b6610f5d-d2eb-499e-e8d0-a0c2db5f9b74"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[0., 0.],\n",
              "        [0., 0.]])"
            ]
          },
          "execution_count": 13,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sumprod.clamp_min_(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vpb3vZvuGkyX"
      },
      "outputs": [],
      "source": [
        "pooling_layer_output = torch.max(sumprod)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NfeX-EYuGmJ3"
      },
      "outputs": [],
      "source": [
        "intermediate_output_value = pooling_layer_output * lin_w + lin_b"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "id": "rwA6srUgGniP",
        "outputId": "8893187a-7f02-4e23-e6ea-6eb7f1239594"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[0.0042]])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1625: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
            "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
          ]
        }
      ],
      "source": [
        "from torch.nn import functional as F # torch library for numpy like functions\n",
        "print(F.sigmoid(intermediate_output_value))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h6QhLf0xGpIE"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "name": "CNN_working_details.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.17"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}

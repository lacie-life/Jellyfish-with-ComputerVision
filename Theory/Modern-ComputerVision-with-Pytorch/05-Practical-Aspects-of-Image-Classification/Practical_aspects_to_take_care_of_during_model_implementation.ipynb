{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practical aspects to take care of during model implementation\n",
    "\n",
    "So far, we have seen the various ways of building an image classification model. In\n",
    "this section, we will learn about some of the practical considerations that need to be\n",
    "taken care of when building models. The ones we will discuss in this chapter are as\n",
    "follows:\n",
    "\n",
    "- Dealing with imbalanced data\n",
    "- The size of an object within an image when performing classification\n",
    "- The difference between training and validation images\n",
    "- The number of convolutional and pooling layers in a network\n",
    "- Image sizes to train on GPUs\n",
    "- Leveraging OpenCV utilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dealing with imbalanced data\n",
    "\n",
    "Imagine a scenario where you are trying to predict an object that occurs very rarely\n",
    "within our dataset – let's say in 1% of the total images. For example, this can be the\n",
    "task of predicting whether an X-ray image suggests a rare lung infection.\n",
    "\n",
    "How do we measure the accuracy of the model that is trained to predict the rare lung\n",
    "infection? If we simply predict a class of no infection for all images, the accuracy of\n",
    "classification is 99%, while still being useless. A confusion matrix that depicts the\n",
    "number of times the rare object class has occurred and the number of times the model\n",
    "predicted the rare object class correctly comes in handy in this scenario. Thus, the\n",
    "right set of metrics to look at in this scenario is the metrics related to the confusion\n",
    "matrix.\n",
    "\n",
    "A typical confusion matrix looks as follows:\n",
    "\n",
    "![imgs](./imgs/2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the preceding confusion matrix, 0 stands for no infection and 1 stands for infection.\n",
    "Typically, we would fill up the matrix to understand how accurate our model is.\n",
    "\n",
    "Next comes the question of ensuring that the model gets trained. Typically, the loss\n",
    "function (binary or categorical cross-entropy) takes care of ensuring that the loss\n",
    "values are high when the amount of misclassification is high. However, in addition to\n",
    "the loss function, we can also assign a higher weight to the rarely occurring class,\n",
    "thereby ensuring that we explicitly mention to the model that we want to correctly\n",
    "classify the rare class images.\n",
    "\n",
    "In addition to assigning class weights, we have already seen that image augmentation\n",
    "and/or transfer learning help considerably in improving the accuracy of the model.\n",
    "Furthermore, when augmenting an image, we can over-sample the rare class images\n",
    "to increase their mix in the overall population."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The size of the object within an image\n",
    "\n",
    "Imagine a scenario where the presence of a small patch within a large image dictates\n",
    "the class of the image – for example, lung infection identification where the presence\n",
    "of certain tiny nodules indicates an incident of the disease. In such a scenario, image\n",
    "classification is likely to result in inaccurate results, as the object occupies a smaller\n",
    "portion of the entire image. Object detection comes in handy in this scenario (which\n",
    "we will study in the next chapter).\n",
    "\n",
    "A high-level intuition to solve these problems would be to first divide the input\n",
    "images into smaller grid cells (let's say a 10 x 10 grid) and then identify whether a\n",
    "grid cell contains the object of interest.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dealing with the difference between training and validation data\n",
    "\n",
    "Imagine a scenario where you have built a model to predict whether the image of an\n",
    "eye indicates that the person is likely to be suffering from diabetic retinopathy. To\n",
    "build the model, you have collected data, curated it, cropped it, normalized it, and\n",
    "then finally built a model that has very high accuracy on validation images. However,\n",
    "hypothetically, when the model is used in a real setting (let's say by a doctor/nurse),\n",
    "the model is not able to predict well. Let's understand a few possible reasons why:\n",
    "\n",
    "<b> Are the images taken at the doctor's office similar to the images used to\n",
    "train the model? </b>\n",
    "\n",
    "- Images used when training and real-world images could be very\n",
    "different if you built a model on a curated set of data that has all the\n",
    "preprocessing done, while the images taken at the doctor's end are\n",
    "non-curated.\n",
    "\n",
    "- Images could be different if the device used to capture images at the\n",
    "doctor's office has a different resolution of capturing images when\n",
    "compared to the device used to collect images that are used for\n",
    "training.\n",
    "\n",
    "- Images can be different if there are different lighting conditions at\n",
    "which the images are getting captured in both places.\n",
    "Are the subjects (images) representative enough of the overall population?\n",
    "\n",
    "- Images are representative if they are trained on images of the male\n",
    "population but are tested on the female population, or if, in general,\n",
    "the training and real-world images correspond to different\n",
    "demographics.\n",
    "\n",
    "<b> Is the training and validation split done methodically? </b>\n",
    "\n",
    "- Imagine a scenario where there are 10,000 images and the first 5,000\n",
    "images belong to one class and the last 5,000 images belong to another\n",
    "class. When building a model, if we do not randomize but split the\n",
    "dataset into training and validation with consecutive indices (without\n",
    "random indices), we are likely to see a higher representation of one\n",
    "class while training and of the other class during validation.\n",
    "\n",
    "\n",
    "In general, we need to ensure that the training, validation, and real-world images all\n",
    "have similar data distribution before an end user leverages the system."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The number of nodes in the flatten layer\n",
    "\n",
    "Consider a scenario where you are working on images that are 300 x 300 in\n",
    "dimensions. Technically, we can perform more than five convolutional pooling\n",
    "operations to get the final layer that has as many features as possible. Furthermore,\n",
    "we can have as many channels as we want in this scenario within a CNN. Practically,\n",
    "though, in general, we would design a network so that it has 500–5,000 nodes in the\n",
    "flatten layer.\n",
    "\n",
    "But, if we have a\n",
    "greater number of nodes in the flatten layer, we would have a very high number of\n",
    "parameters when the flatten layer is connected to the subsequent dense layer before\n",
    "connecting to the final classification layer.\n",
    "\n",
    "In general, it is good practice to have a pre-trained model that obtains the flatten layer\n",
    "so that relevant filters are activated as appropriate. Furthermore, when leveraging\n",
    "pre-trained models, make sure to freeze the parameters of the pre-trained model.\n",
    "\n",
    "Generally, the number of trainable parameters in a CNN can be anywhere between 1\n",
    "million to 10 million in a less complex classification exercise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image size\n",
    "\n",
    "Let's say we are working on images that are of very high dimensions – for example,\n",
    "2,000 x 1,000 in shape. When working on such large images, we need to consider the\n",
    "following possibilities:\n",
    "\n",
    "- Can the images be resized to lower dimensions? Images of objects might\n",
    "not lose information if resized; however, images of text documents might\n",
    "lose considerable information if resized to a smaller size.\n",
    "\n",
    "- Can we have a lower batch size so that the batch fits into GPU memory?\n",
    "Typically, if we are working with large images, there is a good chance that\n",
    "for the given batch size, the GPU memory is not sufficient to perform\n",
    "computations on the batch of images.\n",
    "\n",
    "- Do certain portions of the image contain the majority of the information,\n",
    "and hence can the rest of the image be cropped?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Leveraging OpenCV utilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imagine a scenario where you have to move a model to production; less complexity is\n",
    "generally preferable in such a scenario – sometimes even at the cost of accuracy. If\n",
    "any OpenCV module solves the problem that you are already trying to solve, in\n",
    "general, it should be preferred over building a model (unless building a model from\n",
    "scratch gives a considerable boost in accuracy than leveraging off-the-shelf modules)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda-pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
